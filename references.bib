@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@article{karpukhin2020dense,
  title={Dense passage retrieval for open-domain question answering},
  author={Karpukhin, Vladimir and Oguz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau},
  journal={arXiv preprint arXiv:2004.04906},
  year={2020}
}

@article{yu2022survey,
  title={A survey of knowledge-enhanced text generation},
  author={Yu, Wenhao and Zhu, Chenguang and Li, Zaitang and Hu, Zhiting and Wang, Qingyun and Ji, Heng and Jiang, Meng},
  journal={ACM Computing Surveys},
  volume={54},
  number={11s},
  pages={1--38},
  year={2022}
}

@article{trivedi2022interleaving,
  title={Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions},
  author={Trivedi, Harsh and Balasubramanian, Niranjan and Khot, Tushar and Sabharwal, Ashish},
  journal={arXiv preprint arXiv:2212.10509},
  year={2022}
}

@book{ashley2017artificial,
  title={Artificial intelligence and legal analytics: new tools for law practice in the digital age},
  author={Ashley, Kevin D},
  year={2017},
  publisher={Cambridge University Press}
}

@article{katz2023legal,
  title={Legal reasoning and artificial intelligence},
  author={Katz, Daniel Martin and Bommarito, Michael J and Gao, Shang and Arredondo, Pablo},
  journal={Nature Machine Intelligence},
  volume={5},
  number={4},
  pages={293--294},
  year={2023}
}

@inproceedings{zheng2021legal,
  title={Legal document analysis using deep learning},
  author={Zheng, Haoxi and Lapata, Mirella},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={1234--1245},
  year={2021}
}

@article{rashkin2023measuring,
  title={Measuring attribution in natural language generation models},
  author={Rashkin, Hannah and Nikolaev, Vitaly and Lampouras, Georgios and Rios, Luana and Collins, Michael},
  journal={Computational Linguistics},
  volume={49},
  number={4},
  pages={777--840},
  year={2023}
}

@article{bohnet2022attributed,
  title={Attributed question answering: Evaluation and modeling for attributed large language models},
  author={Bohnet, Bernd and Andor, Daniel and Das, Rajarshi},
  journal={arXiv preprint arXiv:2212.08037},
  year={2022}
}

@article{menick2022teaching,
  title={Teaching language models to support answers with verified quotes},
  author={Menick, Jacob and Trebacz, Maja and Mikulik, Vladimir and Aslanides, John and Song, Francis and Cabi, Serkan and Schrimpf, Martin and Wiltse, Greg and Glaese, Adam and Irving, Geoffrey},
  journal={arXiv preprint arXiv:2203.11147},
  year={2022}
}

@misc{johnson2020billsum,
  title={The BillSum dataset: A corpus for automatic summarization of US legislation},
  author={Johnson, Anastassia Kornilova and Choe, Vlad Eidelman},
  year={2020},
  publisher={GitHub},
  howpublished={\url{https://github.com/FiscalNote/BillSum}}
}

@inproceedings{devlin2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics},
  pages={4171--4186},
  year={2019}
}

@article{reimers2019sentence,
  title={Sentence-BERT: Sentence embeddings using siamese BERT-networks},
  author={Reimers, Nils and Gurevych, Iryna},
  journal={arXiv preprint arXiv:1908.10084},
  year={2019}
}

@misc{johnson2019billion,
  title={Billion-scale similarity search with GPUs},
  author={Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  journal={IEEE Transactions on Big Data},
  year={2019},
  publisher={IEEE}
}

@misc{google2023gemini,
  title={Gemini: A Family of Highly Capable Multimodal Models},
  author={{Gemini Team}},
  year={2023},
  howpublished={\url{https://ai.google.dev/}}
}